To analyse whether the average summer month temperature is rising, we use a linear model with Gaussian model for the unexplained variation.
## Gaussian linear model with adjustable priors
The folloing Stan code allows also setting hyperparameter values as data allowing easier way to use different priors in different analyses:
```{r}
writeLines(readLines("lin.stan"))
```
Create another list with data and priors
```{r}
d_lin_priors <- c(list(
pmualpha = mean(unlist(d_kilpis[,5])), # centered
psalpha = 100, # weakly informative
pmubeta = 0, # a priori incr. and decr. as likely
psbeta = (.1--.1)/6), # avg temp prob does does not incr. more than a degree per 10 years
d_lin)
```
Run Stan
```{r, results='hide'}
fit_lin <- stan(file = 'lin.stan', data = d_lin_priors, seed = SEED)
```
Stan gives a warning: There were `r get_num_max_treedepth(fit_lin)` transitions after warmup that exceeded the maximum treedepth. You can use ShinyStan (```launch_shinystan(fit_lin)```) to look at the treedepth info and joint posterior of alpha and beta, to get a hint for the reason. ShinyStan helps also checking divergences, energy diagnostic, n_eff's and Rhats.
Instead of interactive ShinyStan, we can also check the diagnostics as follows
```{r}
monitor(fit_lin, probs = c(0.1, 0.5, 0.9))
```
The following diagnostics are explained in [Robust Statistical Workflow with RStan Case Study](http://mc-stan.org/users/documentation/case-studies/rstan_workflow.html) by Michael Betancourt.
```{r, message=TRUE}
check_hmc_diagnostics(fit_lin)
```
Compute the probability that the summer temperature is increasing.
```{r}
samples_lin <- rstan::extract(fit_lin, permuted = T)
mean(samples_lin$beta>0) # probability that beta > 0
```
Plot the data, the model fit and prediction for year 2016.
```{r}
mu <- apply(samples_lin$mu, 2, quantile, c(0.05, 0.5, 0.95)) %>%
t() %>% data.frame(x = d_lin$x, .)  %>% gather(pct, y, -x)
pfit <- ggplot() +
geom_point(aes(x, y), data = data.frame(d_lin), size = 1) +
geom_line(aes(x, y, linetype = pct), data = mu, color = 'red') +
scale_linetype_manual(values = c(2,1,2)) +
labs(y = 'Summer temp. @Kilpisjärvi', x= "Year") +
guides(linetype = F)
pars <- intersect(names(samples_lin), c('beta','sigma','ypred'))
draws <- as.data.frame(fit_lin)
phist <- mcmc_hist(draws, pars = pars)
grid.arrange(pfit, phist, nrow = 2)
```
## Gaussian linear model with standardized data
In the above we used the unnormalized data and as x values are far away from zero, this will cause very strong posterior dependency between alpha and beta (did you use ShinyStan for the above model?). The strong posterior dependency can be removed by normalizing the data to have zero mean. The following Stan code makes it in Stan. In generated quantities we do correspnding transformation back to the original scale.
```{r}
writeLines(readLines("lin_std.stan"))
```
```{r, results='hide'}
fit_lin_std <- stan(file = 'lin_std.stan', data = d_lin, seed = SEED)
```
Now there were no warnings. You can use ShinyStan (```launch_shinystan(fit_lin)```) to look at the posterior and diagnostics and compare to the previous model results. We can also check diagnostics with the following commands.
```{r, message=TRUE}
monitor(fit_lin_std, probs = c(0.1, 0.5, 0.9))
check_hmc_diagnostics(fit_lin_std)
```
We see that there are no warnings by diagnostics and n_eff's are higher than with the previous case with non-standardized data.
Next we check that we get similar probability for beta>0.
```{r}
samples_lin_std <- rstan::extract(fit_lin_std, permuted = T)
mean(samples_lin_std$beta>0) # probability that beta > 0
```
# Linear Student's t model.
The temperatures used in the above analyses are averages over three months, which makes it more likely that they are normally distributed, but there can be extreme events in the feather and we can check whether more robust Student's t observation model woul give different results.
```{r}
writeLines(readLines("lin_t.stan"))
```
```{r, results='hide'}
fit_lin_t <- stan(file = 'lin_t.stan', data = d_lin, seed = SEED)
```
We get some warnings, but these specific warnings are not critical if counts are small as here.
Let's examine further diagnostics.
```{r, message=TRUE}
monitor(fit_lin_t, probs = c(0.1, 0.5, 0.9))
check_hmc_diagnostics(fit_lin_t)
```
We get similar diagnostics as for the linear Gaussian model with non-standardised data.
Compute the probability that the summer temperature is increasing.
```{r}
samples_lin_t <- extract(fit_lin_t, permuted = T)
mean(samples_lin_t$beta>0) # probability that beta > 0
```
We get similar probability as with Gaussian obervation model.
Plot data and the model fit
```{r}
mu <- apply(samples_lin_t$mu, 2, quantile, c(0.05, 0.5, 0.95)) %>%
t() %>% data.frame(x = d_lin$x, .)  %>% gather(pct, y, -x)
pfit <- ggplot() +
geom_point(aes(x, y), data = data.frame(d_lin), size = 1) +
geom_line(aes(x, y, linetype = pct), data = mu, color = 'red') +
scale_linetype_manual(values = c(2,1,2)) +
labs(y = 'Summer temp. @Kilpisjärvi', x= "Year") +
guides(linetype = F)
pars <- intersect(names(samples_lin_t), c('beta','sigma','nu','ypred'))
draws <- as.data.frame(fit_lin_t)
phist <- mcmc_hist(draws, pars = pars)
grid.arrange(pfit, phist, nrow = 2)
```
We see also that the marginal posterior of nu is wide with lot of mass for values producing distrbution really close to Gaussian.
# Pareto-smoothed importance-sampling leave-one-out cross-validation (PSIS-LOO)
We can use leave-one-out cross-validation to compare the expected predictive performance. For the following three lines to execute, the log-likelihood needs to be evaluated in the stan code. For an example, see lin.stan and [Computing approximate leave-one-out cross-validation usig PSIS-LOO](http://mc-stan.org/loo/articles/loo2-with-rstan.html).
```{r}
log_lik <- extract_log_lik(fit_lin, merge_chains = FALSE)
r_eff <- relative_eff(exp(log_lik))
loo_lin <- loo(log_lik, r_eff = r_eff)
log_lik_t <- extract_log_lik(fit_lin_t, merge_chains = FALSE)
r_eff_t <- relative_eff(exp(log_lik))
loo_lin_t <- loo(log_lik_t, r_eff = r_eff_t)
compare(loo_lin, loo_lin_t)
```
There is no practical difference between Gaussian and Student's t observation model for this data.
# Comparison of k groups with hierarchical models
Let's compare the temperatures in three summer months.
```{r}
d_kilpis <- read.delim('kilpisjarvi-summer-temp.csv', sep = ';')
d_grp <-list(N = 3*nrow(d_kilpis),
K = 3,
x = rep(1:3, nrow(d_kilpis)),
y = c(t(d_kilpis[,2:4])))
```
# Common variance (ANOVA) model
```{r}
writeLines(readLines("grp_aov.stan"))
```
Fit the model
```{r, results='hide'}
fit_grp <- stan(file = 'grp_aov.stan', data = d_grp, seed = SEED)
```
```{r}
monitor(fit_grp, probs = c(0.1, 0.5, 0.9))
```
## Common variance and hierarchical prior for mean.
Results do not differ much from the previous, because there is only
few groups and quite much data per group, but this works as an example of a hierarchical model.
```{r}
writeLines(readLines("grp_prior_mean.stan"))
```
Fit the model
```{r, results='hide'}
fit_grp <- stan(file = 'grp_prior_mean.stan', data = d_grp, seed = SEED)
```
```{r}
monitor(fit_grp, probs = c(0.1, 0.5, 0.9))
```
## Unequal variance and hierarchical prior for mean and variance
```{r}
writeLines(readLines("grp_prior_mean_var.stan"))
```
Fit the model
```{r, results='hide'}
fit_grp <- stan(file = 'grp_prior_mean_var.stan', data = d_grp, seed = SEED)
```
```{r}
monitor(fit_grp, probs = c(0.1, 0.5, 0.9))
```
Plot the results
```{r}
samples_grp <- extract(fit_grp, permuted = T)
temps <- data.frame(samples_grp$mu) %>%
setNames(c('June','July','August'))
mcmc_areas(temps) + xlab('Temperature')
```
Probabilities that June is hotter than July, June is hotter than August
and July is hotter than August:
```{r}
paste('p(TempJun > TempJul) = ', mean(temps$June > temps$July))
paste('p(TempJun > TempAug) = ', mean(temps$June > temps$August))
paste('p(TempJul > TempAug) = ', mean(temps$July > temps$August))
```
<br />
# Licenses {.unnumbered}
* Code &copy; 2017-2018, Aki Vehtari, 2017 Markus Paasiniemi, licensed under BSD-3.
* Text &copy; 2017-2018, Aki Vehtari, licensed under CC-BY-NC 4.0.
knitr::opts_chunk$set(cache=FALSE, message=FALSE, error=FALSE, warning=TRUE, comment=NA, out.width='95%')
library(tidyr)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
library(loo)
library(ggplot2)
library(gridExtra)
library(bayesplot)
theme_set(bayesplot::theme_default(base_family = "sans"))
library(shinystan)
install.packages("shinystan")
knitr::opts_chunk$set(cache=FALSE, message=FALSE, error=FALSE, warning=TRUE, comment=NA, out.width='95%')
library(tidyr)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
library(loo)
library(ggplot2)
library(gridExtra)
library(bayesplot)
theme_set(bayesplot::theme_default(base_family = "sans"))
library(shinystan)
source('stan_utility.R')
SEED <- 48927 # set random seed for reproducability
d_bern <- list(N = 10, y = c(1, 1, 1, 0, 1, 1, 1, 0, 1, 0))
writeLines(readLines("bern.stan"))
fit_bern <- stan(file = 'bern.stan', data = d_bern, seed = SEED)
monitor(fit_bern, probs = c(0.1, 0.5, .9))
draws <- as.data.frame(fit_bern)
mcmc_hist(draws, pars='theta')
# or with base R
# hist(draws[,'theta'])
d_bin <- list(N = 10, y = 7)
writeLines(readLines("binom.stan"))
fit_bin <- stan(file = 'binom.stan', data = d_bin, seed = SEED)
monitor(fit_bin, probs = c(0.1, 0.5, 0.9))
draws <- as.data.frame(fit_bin)
mcmc_hist(draws, pars = 'theta')
d_bin <- list(N = 100, y = 70)
fit_bin <- stan(file = 'binom.stan', data = d_bin, seed = SEED)
monitor(fit_bin, probs = c(0.1, 0.5, 0.9))
draws <- as.data.frame(fit_bin)
mcmc_hist(draws, pars = 'theta')
writeLines(readLines("binomb.stan"))
d_bin <- list(N = 100, y = 70)
fit_bin <- stan(file = 'binomb.stan', data = d_bin, seed = SEED)
monitor(fit_bin, probs = c(0.1, 0.5, 0.9))
draws <- as.data.frame(fit_bin)
mcmc_hist(draws, pars = 'theta')
d_bin2 <- list(N1 = 674, y1 = 39, N2 = 680, y2 = 22)
writeLines(readLines("binom2.stan"))
fit_bin2 <- stan(file = 'binom2.stan', data = d_bin2, seed = SEED)
monitor(fit_bin2, probs = c(0.1, 0.5, 0.9))
draws <- as.data.frame(fit_bin2)
mcmc_hist(draws, pars = 'oddsratio') +
geom_vline(xintercept = 1) +
scale_x_continuous(breaks = c(seq(0.25,1.5,by=0.25)))
d_kilpis <- read.delim('kilpisjarvi-summer-temp.csv', sep = ';')
d_lin <-list(N = nrow(d_kilpis),
x = d_kilpis$year,
xpred = 2016,
y = d_kilpis[,5])
ggplot() +
geom_point(aes(x, y), data = data.frame(d_lin), size = 1) +
labs(y = 'Summer temp. @Kilpisjärvi', x= "Year") +
guides(linetype = F)
writeLines(readLines("lin.stan"))
d_lin_priors <- c(list(
pmualpha = mean(unlist(d_kilpis[,5])), # centered
psalpha = 100, # weakly informative
pmubeta = 0, # a priori incr. and decr. as likely
psbeta = (.1--.1)/6), # avg temp prob does does not incr. more than a degree per 10 years
d_lin)
fit_lin <- stan(file = 'lin.stan', data = d_lin_priors, seed = SEED)
monitor(fit_lin, probs = c(0.1, 0.5, 0.9))
check_hmc_diagnostics(fit_lin)
samples_lin <- rstan::extract(fit_lin, permuted = T)
mean(samples_lin$beta>0) # probability that beta > 0
mu <- apply(samples_lin$mu, 2, quantile, c(0.05, 0.5, 0.95)) %>%
t() %>% data.frame(x = d_lin$x, .)  %>% gather(pct, y, -x)
pfit <- ggplot() +
geom_point(aes(x, y), data = data.frame(d_lin), size = 1) +
geom_line(aes(x, y, linetype = pct), data = mu, color = 'red') +
scale_linetype_manual(values = c(2,1,2)) +
labs(y = 'Summer temp. @Kilpisjärvi', x= "Year") +
guides(linetype = F)
pars <- intersect(names(samples_lin), c('beta','sigma','ypred'))
draws <- as.data.frame(fit_lin)
phist <- mcmc_hist(draws, pars = pars)
grid.arrange(pfit, phist, nrow = 2)
writeLines(readLines("lin_std.stan"))
fit_lin_std <- stan(file = 'lin_std.stan', data = d_lin, seed = SEED)
monitor(fit_lin_std, probs = c(0.1, 0.5, 0.9))
check_hmc_diagnostics(fit_lin_std)
samples_lin_std <- rstan::extract(fit_lin_std, permuted = T)
mean(samples_lin_std$beta>0) # probability that beta > 0
writeLines(readLines("lin_t.stan"))
fit_lin_t <- stan(file = 'lin_t.stan', data = d_lin, seed = SEED)
monitor(fit_lin_t, probs = c(0.1, 0.5, 0.9))
check_hmc_diagnostics(fit_lin_t)
samples_lin_t <- extract(fit_lin_t, permuted = T)
mean(samples_lin_t$beta>0) # probability that beta > 0
mu <- apply(samples_lin_t$mu, 2, quantile, c(0.05, 0.5, 0.95)) %>%
t() %>% data.frame(x = d_lin$x, .)  %>% gather(pct, y, -x)
pfit <- ggplot() +
geom_point(aes(x, y), data = data.frame(d_lin), size = 1) +
geom_line(aes(x, y, linetype = pct), data = mu, color = 'red') +
scale_linetype_manual(values = c(2,1,2)) +
labs(y = 'Summer temp. @Kilpisjärvi', x= "Year") +
guides(linetype = F)
pars <- intersect(names(samples_lin_t), c('beta','sigma','nu','ypred'))
draws <- as.data.frame(fit_lin_t)
phist <- mcmc_hist(draws, pars = pars)
grid.arrange(pfit, phist, nrow = 2)
log_lik <- extract_log_lik(fit_lin, merge_chains = FALSE)
r_eff <- relative_eff(exp(log_lik))
loo_lin <- loo(log_lik, r_eff = r_eff)
log_lik_t <- extract_log_lik(fit_lin_t, merge_chains = FALSE)
r_eff_t <- relative_eff(exp(log_lik))
loo_lin_t <- loo(log_lik_t, r_eff = r_eff_t)
compare(loo_lin, loo_lin_t)
d_kilpis <- read.delim('kilpisjarvi-summer-temp.csv', sep = ';')
d_grp <-list(N = 3*nrow(d_kilpis),
K = 3,
x = rep(1:3, nrow(d_kilpis)),
y = c(t(d_kilpis[,2:4])))
writeLines(readLines("grp_aov.stan"))
fit_grp <- stan(file = 'grp_aov.stan', data = d_grp, seed = SEED)
monitor(fit_grp, probs = c(0.1, 0.5, 0.9))
writeLines(readLines("grp_prior_mean.stan"))
fit_grp <- stan(file = 'grp_prior_mean.stan', data = d_grp, seed = SEED)
monitor(fit_grp, probs = c(0.1, 0.5, 0.9))
writeLines(readLines("grp_prior_mean_var.stan"))
fit_grp <- stan(file = 'grp_prior_mean_var.stan', data = d_grp, seed = SEED)
monitor(fit_grp, probs = c(0.1, 0.5, 0.9))
samples_grp <- extract(fit_grp, permuted = T)
temps <- data.frame(samples_grp$mu) %>%
setNames(c('June','July','August'))
mcmc_areas(temps) + xlab('Temperature')
paste('p(TempJun > TempJul) = ', mean(temps$June > temps$July))
paste('p(TempJun > TempAug) = ', mean(temps$June > temps$August))
paste('p(TempJul > TempAug) = ', mean(temps$July > temps$August))
writeLines(readLines("bern.stan"))
rmarkdown::render()
rmarkdown::render(rstan_demo.Rmd)
rmarkdown::render(rstan_demo.Rmd)
setwd('/media/zheqng/Seagate Backup Plus Drive/zheqng@nwu/文档/teaching lectures/2019年春季MCMC选讲/BDA_R_demos-master/demos_rstan/')
rmarkdown::render(rstan_demo.Rmd)
library(tidyr)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
library(loo)
library(ggplot2)
library(gridExtra)
library(bayesplot)
theme_set(bayesplot::theme_default(base_family = "sans"))
library(shinystan)
source('stan_utility.R')
SEED <- 48927 # set random seed for reproducability
d_bern <- list(N = 10, y = c(1, 1, 1, 0, 1, 1, 1, 0, 1, 0))
d_bern
fit_bern <- stan(file = 'bern.stan', data = d_bern, seed = SEED)
monitor(fit_bern, probs = c(0.1, 0.5, .9))
draws <- as.data.frame(fit_bern)
mcmc_hist(draws, pars='theta')
d_kilpis <- read.delim('kilpisjarvi-summer-temp.csv', sep = ';')
d_lin <-list(N = nrow(d_kilpis),
x = d_kilpis$year,
xpred = 2016,
y = d_kilpis[,5])
ggplot() +
geom_point(aes(x, y), data = data.frame(d_lin), size = 1) +
labs(y = 'Summer temp. @Kilpisjärvi', x= "Year") +
guides(linetype = F)
d_lin_priors <- c(list(
pmualpha = mean(unlist(d_kilpis[,5])), # centered
psalpha = 100, # weakly informative
pmubeta = 0, # a priori incr. and decr. as likely
psbeta = (.1--.1)/6), # avg temp prob does does not incr. more than a degree per 10 years
d_lin)
fit_lin <- stan(file = 'lin.stan', data = d_lin_priors, seed = SEED)
monitor(fit_lin, probs = c(0.1, 0.5, 0.9))
check_hmc_diagnostics(fit_lin)
?matrix
matrx(c(1,0.8,0.8,1),nrow=2)
matrix(c(1,0.8,0.8,1),nrow=2)
y=c(0,0)
fit_bi_norn<-stan(file = 'bi_norm.stan',data = y, seed = SEED)
y=list(N=2,c(0,0))
fit_bi_norn<-stan(file = 'bi_norm.stan',data = y, seed = SEED)
setwd('/media/zheqng/Seagate Backup Plus Drive/zheqng@nwu/文档/teaching lectures/2019年春季MCMC选讲/my R demos/')
y=list(N=2,c(0,0))
fit_bi_norn<-stan(file = 'bi_norm.stan',data = y, seed = SEED)
fit_bi_norn<-stan(file = 'bi_norm.stan',data = y, seed = SEED)
fit_bi_norn<-stan(file = 'bi_norm.stan',data = y, seed = SEED)
diag(2)
fit_bi_norn<-stan(file = 'bi_norm.stan',data = y, seed = SEED)
?stan
y=list(N=100,rnorm(100))
fit_bi_norn<-stan(file = 'bi_norm.stan',data = y, seed = SEED)
fit_bi_norn<-stan(file = 'bi_norm.stan',data = y, seed = SEED)
fit_bi_norn<-stan(file = 'bi_norm.stan',data = y, seed = SEED)
fit_bi_norn<-stan(file = 'bi_norm.stan',data = y, seed = SEED)
rm(list=ls())										#清空当前工作空间
a=read.csv("D:/Practical Business Data Analysis/case/CH2/real.csv",header=T)		#读入csv格式的数据，赋值为a
a=read.csv("real.csv",header=T)		#读入csv格式的数据，赋值为a
getwd()
setwd("/media/zheqng/Seagate Backup Plus Drive/zheqng@nwu/文档/teaching lectures/2019年春季应用商务统计分析/程序/CH2/")
a=read.csv("real.csv",header=T)		#读入csv格式的数据，赋值为a
a=read.csv("real.csv",header=T)		#读入csv格式的数据，赋值为a
View(a)
View(a)
attach(a)										#将数据集a中个变量添加到工作空间，便与直接调用
View(a)
?attach
pairs(a[,c(1:6)])									#对a的前6列做散点图
boxplot(price~ring)									#画出price与ring之间的盒状图
log.price=log(price)									#对price对数变化，并赋值给log.price
boxplot(log.price~ring)									#画出log.price与ring之间的盒状图
par(mfrow=c(2,2))									#设置画图模式2x2的格式
boxplot(log.price~dis)									#画出log.price与dis之间的盒状图
boxplot(log.price~wuye)									#画出log.price与wuye之间的盒状图
boxplot(log.price~fitment)								#画出log.price与fitment之间的盒状图
boxplot(log.price~contype)								#画出log.price与contype之间的盒状图
summary(a[,c(1:5)])									#给出a中前5列的描述性分类统计
lm1=lm(log.price~as.factor(ring))							#用离散变量ring做解释性变量做单因子方差分析
?as.factor
ring
as.factor(ring)
aaa = as.factor(ring)
aaa[1]
aa = ring
library(car)										#载入程序包car
Anova(lm1,type="III")									#对模型lm1做三型方差分析
Anova(lm1)									#对模型lm1做三型方差分析
Anova
?Anova
rm(list=ls())										#清空当前工作空间
setwd("/media/zheqng/Seagate Backup Plus Drive/zheqng@nwu/文档/teaching lectures/2019年春季应用商务统计分析/程序/CH2/")
a=read.csv("real.csv",header=T)		#读入csv格式的数据，赋值为a
View(a)
attach(a)										#将数据集a中个变量添加到工作空间，便与直接调用
View(a)
dis
pairs(a[,c(1:6)])									#对a的前6列做散点图
boxplot(price~ring)									#画出price与ring之间的盒状图
rm(list=ls())									#清理当前工作空间
a=read.table("/media/zheqng/Seagate Backup Plus Drive/zheqng@nwu/文档/teaching lectures/2019年春季应用商务统计分析/程序/CH1/roe.txt",header=T)	#读入以空格为分隔符，并带有标题行的文本文件
round(a[1:10,],4)								#用4位小数点的格式显示a中前10行的数据
a1=a[a$year==2002,-1]								#从a中选出year为2002的数据，并删除第1列，然后赋值给a1
Mean=sapply(a1,mean)								#计算a1中各列的均值
Min=sapply(a1,min)								#计算a1中各列的最小值
Median=sapply(a1,median)							#计算a1中各列的中位数
Max=sapply(a1,max)								#计算a1中各列的最大值
SD=sapply(a1,sd)								#计算a1中各列的标准差
cbind(Mean,Min,Median,Max,SD)							#将均值、最小值、中位数、最大值、标准差集中在一起展示
round(cor(a),3)									#计算相关系数，用3位小数点的格式展示
plot(a1$ROEt,a1$ROE)								#画出ROEt和ROE之间的散点图
lm1=lm(ROE~ROEt+ATO+PM+LEV+GROWTH+PB+ARR+INV+ASSET,data=a1)			#用a1中数据拟合线性回归模型
summary(lm1)									#给出模型lm1中系数估计值、P值等细节
round(a1[1:10,],3)								#用3位小数点的格式显示a1中前10行的数据
par(mfrow=c(2,2))								#设置画图为2x2的格式
plot(lm1,which=c(1:4))								#画出lm1中对应于模型检验的4张图，包括残差图、QQ图和Cook距离图
a1=a1[-47,]									#删除a1中第47行的观测
lm2=lm(ROE~ROEt+ATO+PM+LEV+GROWTH+PB+ARR+INV+ASSET,data=a1)			#用上一行命令得到的新数据a1再次拟合线型回归模型，结果赋值给lm2
plot(lm2,which=c(1:4))								#画出lm2中对应于模型检验的4张图，包括残差图、QQ图和Cook距离图
library(car)									#载入程序包Car
round(vif(lm2),2)								#计算模型lm2的方差膨胀因子，用2位小数点的格式展示
lm.aic=step(lm2,trace=F)							#根据AIC准则选出最优模型，并赋值给lm.aic
summary(lm.aic)									#给出模型lm.aic中系数估计值、P值等细节
lm.bic=step(lm2,k=log(length(a1[,1])),trace=F)					#根据BIC准则选出最优模型，并赋值给lm.bic
summary(lm.bic)									#给出模型lm.bic中系数估计值、P值等细节
a2=a[a$year==2003,-1]								#从数据a中选出year为2003的观测，并删除第一列，赋值给a2
round(a2[1:5,],3)								#用3为小数点的格式展示a2的前5行数据
y1=predict(lm2,a2)								#用全模型lm2对a2进行预测
y1
?predict
lm2
summary(lm2)
?lm
?summary
summary(lm2)$coefficients
summary(lm2)$coefficients[,1]
summary(lm2)$residuals
View(a2)
View(a1)
View(a)
a1[c(1:5),-10]
ones(1,2)
rep(1,3)
X = cbind(rep(1,500),a1[,-10])
X = cbind(rep(1,499),a1[,-10])
View(X)
sqrt(1+ t(x0)%*%inv(t(X)%*%X )%*%x0)
x0 = a2[,c(1:9)]
sqrt(1+ t(x0)%*%inv(t(X)%*%X )%*%x0)
?solve
solve(t(X)%*%X ,x0)
t(X)%*%X
?%*%
?*
?multiple
t(X)
size(t(X))
log.price=log(price)									#对price对数变化，并赋值给log.price
boxplot(log.price~ring)
boxplot(price~ring)									#画出price与ring之间的盒状图
rm(list=ls())										#清空当前工作空间
setwd("/media/zheqng/Seagate Backup Plus Drive/zheqng@nwu/文档/teaching lectures/2019年春季应用商务统计分析/程序/CH2/")
a=read.csv("real.csv",header=T)		#读入csv格式的数据，赋值为a
attach(a)										#将数据集a中个变量添加到工作空间，便与直接调用
pairs(a[,c(1:6)])									#对a的前6列做散点图
boxplot(price~ring)									#画出price与ring之间的盒状图
log.price=log(price)									#对price对数变化，并赋值给log.price
boxplot(log.price~ring)									#画出log.price与ring之间的盒状图
par(mfrow=c(2,2))									#设置画图模式2x2的格式
boxplot(log.price~dis)									#画出log.price与dis之间的盒状图
boxplot(log.price~wuye)									#画出log.price与wuye之间的盒状图
boxplot(log.price~fitment)								#画出log.price与fitment之间的盒状图
boxplot(log.price~contype)								#画出log.price与contype之间的盒状图
summary(a[,c(1:5)])									#给出a中前5列的描述性分类统计
lm1=lm(log.price~as.factor(ring))							#用离散变量ring做解释性变量做单因子方差分析
library(car)										#载入程序包car
Anova(lm1,type="III")									#对模型lm1做三型方差分析
summary(lm1)										#显示模型lm1的各方面细节，包括参数估计值、P值等
lm2.1=lm(log.price~as.factor(ring)+as.factor(wuye))					#不带交互作用的双因子方差分析
9.97/4
(9.97/4)/(1.95/195)
(9.97/4)/(16.95/195)
?FDist
pf(28.66,4,195,lower.tail = FALSE)
pf(28.66,4,195,lower.tail = TRUE)
